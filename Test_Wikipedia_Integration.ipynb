{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia Dataset Integration Test\n",
    "\n",
    "This notebook tests the integration of the Wikipedia dataset from Quantum Dice v2.\n",
    "\n",
    "Run all cells to verify the integration is working correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.vector_store import VectorStore\n",
    "from core.embedder import EmbeddingGenerator\n",
    "from core.analysis_utils import evaluate_retrieval_quality, compute_pairwise_similarities\n",
    "import numpy as np\n",
    "\n",
    "print(\"✓ All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Wikipedia ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = VectorStore(\n",
    "    collection_name=\"wiki_aspects\",\n",
    "    persist_directory=\"./data/wikipedia/chroma_db\"\n",
    ")\n",
    "\n",
    "print(f\"✓ ChromaDB loaded!\")\n",
    "print(f\"  Total chunks: {vector_store.count:,}\")\n",
    "\n",
    "# Get statistics\n",
    "stats = vector_store.get_statistics()\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"  Collection: {stats['collection_name']}\")\n",
    "print(f\"  Unique sources: {stats['unique_sources']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check Chunk Type Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count different chunk types\n",
    "chunk_types = {\n",
    "    \"Gold Base\": vector_store.get_by_metadata({\"chunk_type\": \"gold_base\"}),\n",
    "    \"Gold Redundant\": vector_store.get_by_metadata({\"chunk_type\": \"gold_redundant\"}),\n",
    "    \"Noise\": vector_store.get_by_metadata({\"chunk_type\": \"noise\"}),\n",
    "    \"Prompts\": vector_store.get_by_metadata({\"chunk_type\": \"prompt\"}),\n",
    "}\n",
    "\n",
    "print(\"Chunk Distribution:\")\n",
    "for name, chunks in chunk_types.items():\n",
    "    print(f\"  {name:20s}: {len(chunks):,}\")\n",
    "\n",
    "total = sum(len(chunks) for chunks in chunk_types.values())\n",
    "print(f\"\\n  Total: {total:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load BGE-Large Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading BGE-large model (this may take a moment)...\")\n",
    "\n",
    "embedder = EmbeddingGenerator(\n",
    "    model_name=\"BAAI/bge-large-en-v1.5\",\n",
    "    device=\"cpu\"  # Change to \"cuda\" if you have GPU\n",
    ")\n",
    "\n",
    "print(f\"✓ Model loaded!\")\n",
    "print(f\"  Model: BAAI/bge-large-en-v1.5\")\n",
    "print(f\"  Dimension: {embedder.embedding_dim}\")\n",
    "print(f\"  Device: cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Basic Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query\n",
    "query = \"What were the major achievements of ancient Rome?\"\n",
    "\n",
    "print(f\"Query: '{query}'\\n\")\n",
    "\n",
    "# Embed query\n",
    "query_embedding = embedder.embed_query(query)\n",
    "print(f\"✓ Query embedded (shape: {query_embedding.shape})\\n\")\n",
    "\n",
    "# Retrieve results\n",
    "results = vector_store.search(query_embedding, k=5)\n",
    "\n",
    "print(f\"Top 5 Results:\\n\" + \"=\"*80)\n",
    "for i, result in enumerate(results, 1):\n",
    "    chunk_type = result['metadata'].get('chunk_type', 'unknown')\n",
    "    aspect = result['metadata'].get('aspect_name', 'N/A')\n",
    "    \n",
    "    print(f\"\\n[{i}] Score: {result['score']:.4f} | Type: {chunk_type} | Aspect: {aspect}\")\n",
    "    print(f\"    {result['text'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Filtered Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with filters - exclude noise\n",
    "print(\"Filtered Search (excluding noise):\\n\" + \"=\"*80)\n",
    "\n",
    "filtered_results = vector_store.search_with_filters(\n",
    "    query_embedding,\n",
    "    k=5,\n",
    "    exclude_metadata={\"chunk_type\": \"noise\"}\n",
    ")\n",
    "\n",
    "for i, result in enumerate(filtered_results, 1):\n",
    "    chunk_type = result['metadata'].get('chunk_type', 'unknown')\n",
    "    aspect = result['metadata'].get('aspect_name', 'N/A')\n",
    "    redundancy = result['metadata'].get('redundancy_index', 'N/A')\n",
    "    \n",
    "    print(f\"\\n[{i}] Score: {result['score']:.4f} | Type: {chunk_type}\")\n",
    "    print(f\"    Aspect: {aspect} | Redundancy Index: {redundancy}\")\n",
    "    print(f\"    {result['text'][:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Base Chunks Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only gold base chunks (no redundancy)\n",
    "print(\"Gold Base Chunks Only:\\n\" + \"=\"*80)\n",
    "\n",
    "base_results = vector_store.search_with_filters(\n",
    "    query_embedding,\n",
    "    k=5,\n",
    "    metadata_filter={\"chunk_type\": \"gold_base\"}\n",
    ")\n",
    "\n",
    "for i, result in enumerate(base_results, 1):\n",
    "    aspect = result['metadata'].get('aspect_name', 'N/A')\n",
    "    article = result['metadata'].get('article_title', 'N/A')\n",
    "    \n",
    "    print(f\"\\n[{i}] Score: {result['score']:.4f}\")\n",
    "    print(f\"    Article: {article}\")\n",
    "    print(f\"    Aspect: {aspect}\")\n",
    "    print(f\"    {result['text'][:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Load Precomputed Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the precomputed similarity matrix\n",
    "sim_data = np.load('./data/wikipedia/similarity/similarity_matrix.npz')\n",
    "similarity_matrix = sim_data['similarity_matrix']\n",
    "\n",
    "print(f\"✓ Similarity matrix loaded!\")\n",
    "print(f\"  Shape: {similarity_matrix.shape}\")\n",
    "print(f\"  Min similarity: {similarity_matrix.min():.4f}\")\n",
    "print(f\"  Max similarity: {similarity_matrix.max():.4f}\")\n",
    "print(f\"  Mean similarity: {similarity_matrix.mean():.4f}\")\n",
    "print(f\"  Size: {similarity_matrix.nbytes / (1024*1024):.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test Analysis Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test evaluation metrics\n",
    "selected_indices = [0, 5, 10, 15, 20]\n",
    "gold_indices = [0, 5, 10, 15, 20, 25, 30, 35, 40, 45]\n",
    "\n",
    "# Use a subset of the similarity matrix for testing\n",
    "test_sim_matrix = similarity_matrix[:50, :50]\n",
    "\n",
    "metrics = evaluate_retrieval_quality(\n",
    "    selected_indices=selected_indices,\n",
    "    gold_indices=gold_indices,\n",
    "    similarity_matrix=test_sim_matrix\n",
    ")\n",
    "\n",
    "print(\"Retrieval Quality Metrics:\")\n",
    "print(f\"  Gold Recall: {metrics['gold_recall']:.1f}%\")\n",
    "print(f\"  Average Redundancy: {metrics['avg_redundancy']:.4f}\")\n",
    "print(f\"  Gold Percentage: {metrics['gold_percentage']:.1f}%\")\n",
    "\n",
    "print(\"\\n✓ Analysis utilities working!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Sample Different Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multiple queries\n",
    "test_queries = [\n",
    "    \"How did ancient civilizations develop writing systems?\",\n",
    "    \"What were the main causes of World War II?\",\n",
    "    \"Explain the theory of relativity\",\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    query_emb = embedder.embed_query(query)\n",
    "    results = vector_store.search_with_filters(\n",
    "        query_emb,\n",
    "        k=3,\n",
    "        exclude_metadata={\"chunk_type\": \"noise\"}\n",
    "    )\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"  [{i}] Score: {result['score']:.4f}\")\n",
    "        print(f\"      {result['text'][:120]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ Integration Test Complete!\n",
    "\n",
    "If all cells ran successfully, the Wikipedia dataset integration is working correctly.\n",
    "\n",
    "### What We Tested:\n",
    "1. ✓ Module imports\n",
    "2. ✓ ChromaDB loading (5,600 chunks)\n",
    "3. ✓ Chunk type distribution\n",
    "4. ✓ BGE-large embedder\n",
    "5. ✓ Basic retrieval\n",
    "6. ✓ Filtered retrieval\n",
    "7. ✓ Metadata-based queries\n",
    "8. ✓ Precomputed similarity matrix\n",
    "9. ✓ Analysis utilities\n",
    "10. ✓ Multiple query types\n",
    "\n",
    "### Next Steps:\n",
    "- Read `WIKIPEDIA_INTEGRATION.md` for detailed usage instructions\n",
    "- Run `python test_quick_demo.py` for a command-line demo\n",
    "- Experiment with different retrieval strategies (QUBO, MMR)\n",
    "- Try different redundancy filtering levels\n",
    "- Build your own experiments!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
